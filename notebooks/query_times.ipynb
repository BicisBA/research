{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(\"data/status\", format=\"parquet\", partitioning=\"hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con = con.register(\"status\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_ids = con.execute(\"select distinct(station_id) from status\").df()[\"station_id\"].values\n",
    "len(station_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base select + union select with leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 36662\n",
      "CPU times: user 19.9 s, sys: 766 ms, total: 20.7 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for station_id in station_ids[:1]:\n",
    "    df_query = f\"\"\"\n",
    "    WITH base_status AS (select\n",
    "        station_id,\n",
    "        hour,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        status,\n",
    "        make_timestamp(year, month, day, hour, minute, 0.0) as ts,\n",
    "    from\n",
    "        status\n",
    "    where\n",
    "        year = 2022 and\n",
    "        month = 10 and\n",
    "        station_id = {station_id} and\n",
    "        status = 'IN_SERVICE')\"\"\"\n",
    "    df_query += \" union \".join([\n",
    "    f\"\"\"\n",
    "    select\n",
    "        station_id,\n",
    "        hour,\n",
    "        dayofweek(ts) as dow,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        minute(lead(ts, {i}) over (\n",
    "            order by ts asc\n",
    "        ) - ts)  as minutes_bt_check,\n",
    "        lead(num_bikes_available, {i}) over (\n",
    "            order by ts asc\n",
    "        ) as remaining_bikes_available,\n",
    "    from\n",
    "        base_status\n",
    "    \"\"\" for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "    df1 = con.execute(df_query).df().dropna()\n",
    "\n",
    "print(f\"dataset size {len(df1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base select with leads + union select per lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 36662\n",
      "CPU times: user 20.1 s, sys: 751 ms, total: 20.8 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for station_id in station_ids[:1]:\n",
    "    df_query = f\"\"\"\n",
    "    WITH base_status AS (select\n",
    "        station_id,\n",
    "        hour,\n",
    "        dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        status,\n",
    "    \"\"\"\n",
    "    df_query += \"\".join([\n",
    "        f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "        lead(num_bikes_available, {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) as remaining_bikes_available_{i},\"\"\"\n",
    "     for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "    df_query += f\"\"\"\n",
    "    from\n",
    "        status\n",
    "    where\n",
    "        year = 2022 and\n",
    "        month = 10 and\n",
    "        station_id = {station_id} and\n",
    "        status = 'IN_SERVICE')\"\"\"\n",
    "    df_query += \" union \".join([\n",
    "    f\"\"\"\n",
    "    select\n",
    "        station_id,\n",
    "        hour,\n",
    "        dow,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        minutes_bt_check_{i} as minutes_bt_check,\n",
    "        remaining_bikes_available_{i} as remaining_bikes_available,\n",
    "    from\n",
    "        base_status\n",
    "    \"\"\" for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "    df2 = con.execute(df_query).df().dropna()\n",
    "    \n",
    "print(f\"dataset size {len(df1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base select with leads + pandas dataframe rearrenge per lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 36662\n",
      "CPU times: user 1.94 s, sys: 95.3 ms, total: 2.04 s\n",
      "Wall time: 591 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for station_id in station_ids[:1]:\n",
    "    df_query = f\"\"\"\n",
    "    select\n",
    "        station_id,\n",
    "        hour,\n",
    "        dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        status,\n",
    "    \"\"\"\n",
    "    df_query += \"\".join([\n",
    "        f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "        lead(num_bikes_available, {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) as remaining_bikes_available_{i},\"\"\"\n",
    "     for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "    df_query += f\"\"\"\n",
    "    from\n",
    "        status\n",
    "    where\n",
    "        year = 2022 and\n",
    "        month = 10 and\n",
    "        station_id = {station_id} and\n",
    "        status = 'IN_SERVICE'\"\"\"\n",
    "    df3 = con.execute(df_query).df()\n",
    "dfs_to_concat = []\n",
    "for i in list(range(1, 7)) + list(range(7, 18, 3)):\n",
    "    dfs_to_concat.append(df3[[\"station_id\", \"hour\", \"dow\", \"num_bikes_available\", \"num_bikes_disabled\", \"num_docks_available\",\n",
    "                             \"num_docks_disabled\", \"status\",f\"minutes_bt_check_{i}\",\n",
    "                             f\"remaining_bikes_available_{i}\"]].rename(columns={f\"minutes_bt_check_{i}\": \"minutes_bt_check\",\n",
    "                                                                             f\"remaining_bikes_available_{i}\": \"remaining_bikes_available\"}))\n",
    "\n",
    "pd.concat(dfs_to_concat).dropna().drop_duplicates()\n",
    "\n",
    "print(f\"dataset size {len(df1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple stations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all stations in one query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causes kernel crash because runs out of ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_query = f\"\"\"\n",
    "select\n",
    "    station_id,\n",
    "    hour,\n",
    "    dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "    num_bikes_available,\n",
    "    num_bikes_disabled,\n",
    "    num_docks_available,\n",
    "    num_docks_disabled,\n",
    "    status,\n",
    "\"\"\"\n",
    "df_query += \"\".join([\n",
    "    f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "        partition by station_id\n",
    "        order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "    ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "    lead(num_bikes_available, {i}) over (\n",
    "        partition by station_id\n",
    "        order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "    ) as remaining_bikes_available_{i},\"\"\"\n",
    "    for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "df_query += f\"\"\"\n",
    "from\n",
    "    status\n",
    "where\n",
    "    year = 2022 and\n",
    "    month = 10 and\n",
    "    status = 'IN_SERVICE'\"\"\"\n",
    "df_complete = con.execute(df_query).df()\n",
    "\n",
    "dfs_to_concat = []\n",
    "for i in list(range(1, 7)) + list(range(7, 18, 3)):\n",
    "    dfs_to_concat.append(df_complete[[\"station_id\", \"hour\", \"dow\", \"num_bikes_available\", \"num_bikes_disabled\", \"num_docks_available\",\n",
    "                             \"num_docks_disabled\", \"status\",f\"minutes_bt_check_{i}\",\n",
    "                             f\"remaining_bikes_available_{i}\"]].rename(columns={f\"minutes_bt_check_{i}\": \"minutes_bt_check\",\n",
    "                                                                             f\"remaining_bikes_available_{i}\": \"remaining_bikes_available\"}))\n",
    "\n",
    "df_complete = pd.concat(dfs_to_concat).dropna().drop_duplicates()\n",
    "print(f\"dataset size {len(df_complete)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate per station and concat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 408087\n",
      "CPU times: user 18.3 s, sys: 1.4 s, total: 19.7 s\n",
      "Wall time: 5.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_complete = []\n",
    "for station_id in station_ids[:10]:\n",
    "    df_query = f\"\"\"\n",
    "    select\n",
    "        station_id,\n",
    "        hour,\n",
    "        dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "        num_bikes_available,\n",
    "        num_bikes_disabled,\n",
    "        num_docks_available,\n",
    "        num_docks_disabled,\n",
    "        status,\n",
    "    \"\"\"\n",
    "    df_query += \"\".join([\n",
    "        f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "        lead(num_bikes_available, {i}) over (\n",
    "            order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "        ) as remaining_bikes_available_{i},\"\"\"\n",
    "     for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "    df_query += f\"\"\"\n",
    "    from\n",
    "        status\n",
    "    where\n",
    "        year = 2022 and\n",
    "        month = 10 and\n",
    "        station_id = {station_id} and\n",
    "        status = 'IN_SERVICE'\"\"\"\n",
    "    df_complete.append(con.execute(df_query).df())\n",
    "\n",
    "df_complete = pd.concat(df_complete)\n",
    "dfs_to_concat = []\n",
    "for i in list(range(1, 7)) + list(range(7, 18, 3)):\n",
    "    dfs_to_concat.append(df_complete[[\"station_id\", \"hour\", \"dow\", \"num_bikes_available\", \"num_bikes_disabled\", \"num_docks_available\",\n",
    "                             \"num_docks_disabled\", \"status\",f\"minutes_bt_check_{i}\",\n",
    "                             f\"remaining_bikes_available_{i}\"]].rename(columns={f\"minutes_bt_check_{i}\": \"minutes_bt_check\",\n",
    "                                                                             f\"remaining_bikes_available_{i}\": \"remaining_bikes_available\"}))\n",
    "\n",
    "df_complete=pd.concat(dfs_to_concat).dropna().drop_duplicates()\n",
    "print(f\"dataset size {len(df_complete)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get multiple stations with IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 408087\n",
      "CPU times: user 5.03 s, sys: 576 ms, total: 5.61 s\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_query = f\"\"\"\n",
    "select\n",
    "    station_id,\n",
    "    hour,\n",
    "    dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "    num_bikes_available,\n",
    "    num_bikes_disabled,\n",
    "    num_docks_available,\n",
    "    num_docks_disabled,\n",
    "    status,\n",
    "\"\"\"\n",
    "df_query += \"\".join([\n",
    "    f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "        partition by station_id\n",
    "        order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "    ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "    lead(num_bikes_available, {i}) over (\n",
    "        partition by station_id\n",
    "        order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "    ) as remaining_bikes_available_{i},\"\"\"\n",
    "    for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "df_query += f\"\"\"\n",
    "from\n",
    "    status\n",
    "where\n",
    "    year = 2022 and\n",
    "    month = 10 and\n",
    "    station_id IN (\n",
    "\"\"\"\n",
    "df_query += \" , \".join([str(s) for s in station_ids[:10]])\n",
    "df_query += \"\"\") and\n",
    "    status = 'IN_SERVICE'\"\"\"\n",
    "\n",
    "df_complete = con.execute(df_query).df()\n",
    "dfs_to_concat = []\n",
    "for i in list(range(1, 7)) + list(range(7, 18, 3)):\n",
    "    dfs_to_concat.append(df_complete[[\"station_id\", \"hour\", \"dow\", \"num_bikes_available\", \"num_bikes_disabled\", \"num_docks_available\",\n",
    "                             \"num_docks_disabled\", \"status\",f\"minutes_bt_check_{i}\",\n",
    "                             f\"remaining_bikes_available_{i}\"]].rename(columns={f\"minutes_bt_check_{i}\": \"minutes_bt_check\",\n",
    "                                                                             f\"remaining_bikes_available_{i}\": \"remaining_bikes_available\"}))\n",
    "\n",
    "df_complete=pd.concat(dfs_to_concat).dropna().drop_duplicates()\n",
    "print(f\"dataset size {len(df_complete)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp5k0yln6l\n",
      "dataset size 9301095\n",
      "CPU times: user 1min 53s, sys: 13.4 s, total: 2min 7s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 100\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    print(tmpdirname)\n",
    "    for batch_start in range(0, len(station_ids), batch_size):\n",
    "        df_query = f\"\"\"\n",
    "        select\n",
    "            station_id,\n",
    "            hour,\n",
    "            dayofweek(make_timestamp(year, month, day, hour, minute, 0.0)) as dow,\n",
    "            num_bikes_available,\n",
    "            num_bikes_disabled,\n",
    "            num_docks_available,\n",
    "            num_docks_disabled,\n",
    "            status,\n",
    "        \"\"\"\n",
    "        df_query += \"\".join([\n",
    "            f\"\"\"minute(lead(make_timestamp(year, month, day, hour, minute, 0.0), {i}) over (\n",
    "                partition by station_id\n",
    "                order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "            ) - make_timestamp(year, month, day, hour, minute, 0.0)) as minutes_bt_check_{i},\n",
    "            lead(num_bikes_available, {i}) over (\n",
    "                partition by station_id\n",
    "                order by make_timestamp(year, month, day, hour, minute, 0.0) asc\n",
    "            ) as remaining_bikes_available_{i},\"\"\"\n",
    "            for i in list(range(1, 7)) + list(range(7, 18, 3))])\n",
    "        df_query += f\"\"\"\n",
    "        from\n",
    "            status\n",
    "        where\n",
    "            year = 2022 and\n",
    "            month = 10 and\n",
    "            station_id IN (\n",
    "        \"\"\"\n",
    "        df_query += \" , \".join([str(s) for s in station_ids[batch_start:batch_start+batch_size]])\n",
    "        df_query += \"\"\") and\n",
    "            status = 'IN_SERVICE'\"\"\"\n",
    "\n",
    "        df_complete=con.execute(df_query).df()\n",
    "\n",
    "        dfs_to_concat = []\n",
    "        for i in list(range(1, 7)) + list(range(7, 18, 3)):\n",
    "            dfs_to_concat.append(df_complete[[\"station_id\", \"hour\", \"dow\", \"num_bikes_available\", \"num_bikes_disabled\", \"num_docks_available\",\n",
    "                                    \"num_docks_disabled\", \"status\",f\"minutes_bt_check_{i}\",\n",
    "                                    f\"remaining_bikes_available_{i}\"]].rename(columns={f\"minutes_bt_check_{i}\": \"minutes_bt_check\",\n",
    "                                                                                    f\"remaining_bikes_available_{i}\": \"remaining_bikes_available\"}))\n",
    "\n",
    "        del df_complete\n",
    "        pd.concat(dfs_to_concat).dropna().drop_duplicates().to_csv(tmpdirname+f\"/{batch_start}.csv\")\n",
    "\n",
    "    dfs_to_concat = []\n",
    "    for batch_start in range(0, len(station_ids), batch_size):\n",
    "        dfs_to_concat.append(pd.read_csv(tmpdirname+f\"/{batch_start}.csv\"))\n",
    "\n",
    "    df_complete = pd.concat(dfs_to_concat)\n",
    "\n",
    "print(f\"dataset size {len(df_complete)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv(\"avail_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-bicisba-A0HrnKHR-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
